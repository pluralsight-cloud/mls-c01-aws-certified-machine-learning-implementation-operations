{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b6b1606f-44a9-44ef-8697-17a0b8fb2cc2",
   "metadata": {},
   "source": [
    "# SageMaker Auto Scaling Model Endpoints Demo\n",
    " ## Run this notebook using SageMaker Studio Jupyter Lab"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba2f73a7-0287-4022-9fb6-4f6dc557f21e",
   "metadata": {},
   "source": [
    "First install the aiobotocore package which provides an interface to the AWS services that we'll be using"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a75cd64a-7448-427c-b7e6-d5fa122440b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install --upgrade -q aiobotocore"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46f53dc7-ea9a-4966-9549-b64a79992bb1",
   "metadata": {},
   "source": [
    "We also need to install s3fs which enables Python to work with S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0f200cd4-9f9e-47f4-be6b-7ab3c6065878",
   "metadata": {},
   "outputs": [],
   "source": [
    "pip install s3fs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb4ccaff-dc78-400d-a92e-dfcf83f1d30f",
   "metadata": {},
   "source": [
    "Import the libararies we need to build, train and deploy our model, and configure some parameters, including locations for model artifacts in S3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f0c50094-b448-48d7-96c7-de1df6904b8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import boto3\n",
    "import sagemaker\n",
    "import time\n",
    "import json\n",
    "import io\n",
    "from io import StringIO\n",
    "import base64\n",
    "import pprint\n",
    "import re\n",
    "import s3fs\n",
    "\n",
    "from sagemaker.image_uris import retrieve\n",
    "\n",
    "sess = sagemaker.Session()\n",
    "write_bucket = sess.default_bucket()\n",
    "write_prefix = \"fraud-detect-demo\"\n",
    "\n",
    "region = sess.boto_region_name\n",
    "s3_client = boto3.client(\"s3\", region_name=region)\n",
    "sm_client = boto3.client(\"sagemaker\", region_name=region)\n",
    "sm_runtime_client = boto3.client(\"sagemaker-runtime\")\n",
    "sm_autoscaling_client = boto3.client(\"application-autoscaling\")\n",
    "\n",
    "sagemaker_role = sagemaker.get_execution_role()\n",
    "\n",
    "\n",
    "# S3 locations used for parameterizing the notebook run\n",
    "read_bucket = \"sagemaker-sample-files\"\n",
    "read_prefix = \"datasets/tabular/synthetic_automobile_claims\" \n",
    "model_prefix = \"models/xgb-fraud\"\n",
    "\n",
    "data_capture_key = f\"{write_prefix}/data-capture\"\n",
    "\n",
    "# S3 location of trained model artifact\n",
    "model_uri = f\"s3://{read_bucket}/{model_prefix}/fraud-det-xgb-model.tar.gz\"\n",
    "\n",
    "# S3 path where data captured at endpoint will be stored\n",
    "data_capture_uri = f\"s3://{write_bucket}/{data_capture_key}\"\n",
    "\n",
    "# S3 location of test data\n",
    "test_data_uri = f\"s3://{read_bucket}/{read_prefix}/test.csv\" "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4272439d-601a-43f1-a2bf-eb3692c23efa",
   "metadata": {},
   "source": [
    "We're using the SageMaker managed XGBoost image to train our model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d6760c3-afc1-4489-9d54-91f461084b35",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Retrieve the SageMaker managed XGBoost image\n",
    "training_image = retrieve(framework=\"xgboost\", region=region, version=\"1.3-1\")\n",
    "\n",
    "# Specify a unique model name that does not exist\n",
    "model_name = \"fraud-detect-xgb\"\n",
    "primary_container = {\n",
    "                     \"Image\": training_image,\n",
    "                     \"ModelDataUrl\": model_uri\n",
    "                    }\n",
    "\n",
    "model_matches = sm_client.list_models(NameContains=model_name)[\"Models\"]\n",
    "if not model_matches:\n",
    "    model = sm_client.create_model(ModelName=model_name,\n",
    "                                   PrimaryContainer=primary_container,\n",
    "                                   ExecutionRoleArn=sagemaker_role)\n",
    "else:\n",
    "    print(f\"Model with name {model_name} already exists! Change model name to create new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e98a3bb-4983-45f7-8f18-ee3439e95704",
   "metadata": {},
   "source": [
    "Here's our endpoint configuration, including instance couns, and instance type"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c4857e-dbf2-47ed-b318-060f58d6e71c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Endpoint Config name\n",
    "endpoint_config_name = f\"{model_name}-endpoint-config\"\n",
    "\n",
    "# Endpoint config parameters\n",
    "production_variant_dict = {\n",
    "                           \"VariantName\": \"Alltraffic\",\n",
    "                           \"ModelName\": model_name,\n",
    "                           \"InitialInstanceCount\": 1,\n",
    "                           \"InstanceType\": \"ml.m5.xlarge\",\n",
    "                           \"InitialVariantWeight\": 1\n",
    "                          }\n",
    "\n",
    "# Data capture config parameters\n",
    "data_capture_config_dict = {\n",
    "                            \"EnableCapture\": True,\n",
    "                            \"InitialSamplingPercentage\": 100,\n",
    "                            \"DestinationS3Uri\": data_capture_uri,\n",
    "                            \"CaptureOptions\": [{\"CaptureMode\" : \"Input\"}, {\"CaptureMode\" : \"Output\"}]\n",
    "                           }\n",
    "\n",
    "\n",
    "# Create endpoint config if one with the same name does not exist\n",
    "endpoint_config_matches = sm_client.list_endpoint_configs(NameContains=endpoint_config_name)[\"EndpointConfigs\"]\n",
    "if not endpoint_config_matches:\n",
    "    endpoint_config_response = sm_client.create_endpoint_config(\n",
    "                                                                EndpointConfigName=endpoint_config_name,\n",
    "                                                                ProductionVariants=[production_variant_dict],\n",
    "                                                                DataCaptureConfig=data_capture_config_dict\n",
    "                                                               )\n",
    "else:\n",
    "\t\tprint(f\"Endpoint config with name {endpoint_config_name} already exists! Change endpoint config name to create new\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98334912-35e1-4bd3-a0d5-1fde386ac1c8",
   "metadata": {},
   "source": [
    "Next, we deploy the model by creating the endpoint using the endpoint configuration that we created, it takes about 6 minutes to deploy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9588333-db66-450c-8dd8-1ba92b8146e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "endpoint_name = f\"{model_name}-endpoint\"\n",
    "\n",
    "endpoint_matches = sm_client.list_endpoints(NameContains=endpoint_name)[\"Endpoints\"]\n",
    "if not endpoint_matches:\n",
    "    endpoint_response = sm_client.create_endpoint(\n",
    "                                                  EndpointName=endpoint_name,\n",
    "                                                  EndpointConfigName=endpoint_config_name\n",
    "                                                 )\n",
    "else:\n",
    "    print(f\"Endpoint with name {endpoint_name} already exists! Change endpoint name to create new\")\n",
    "\n",
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "status = resp[\"EndpointStatus\"]\n",
    "while status == \"Creating\":\n",
    "    print(f\"Endpoint Status: {status}...\")\n",
    "    time.sleep(60)\n",
    "    resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    status = resp[\"EndpointStatus\"]\n",
    "print(f\"Endpoint Status: {status}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9be264a2-350e-41bd-b8ad-0ce898216b2e",
   "metadata": {},
   "source": [
    "Invoke the endpoint by running some predictions using some sample data that is formatted using serialization and deserialization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f493ffd9-891a-49fe-ad7c-bc241abd193d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fetch test data to run predictions with the endpoint\n",
    "test_df = pd.read_csv(test_data_uri)\n",
    "\n",
    "# For content type text/csv, payload should be a string with commas separating the values for each feature\n",
    "# This is the inference request serialization step\n",
    "# CSV serialization\n",
    "csv_file = io.StringIO()\n",
    "test_sample = test_df.drop([\"fraud\"], axis=1).iloc[:5]\n",
    "test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "payload = csv_file.getvalue()\n",
    "response = sm_runtime_client.invoke_endpoint(\n",
    "                                             EndpointName=endpoint_name,\n",
    "                                             Body=payload,\n",
    "                                             ContentType=\"text/csv\",\n",
    "                                             Accept=\"text/csv\"\n",
    "                                            )\n",
    "\n",
    "# This is the inference response deserialization step\n",
    "# This is a bytes object\n",
    "result = response[\"Body\"].read()\n",
    "# Decoding bytes to a string\n",
    "result = result.decode(\"utf-8\")\n",
    "# Converting to list of predictions\n",
    "result = re.split(\",|\\n\",result)\n",
    "\n",
    "prediction_df = pd.DataFrame()\n",
    "prediction_df[\"Prediction\"] = result[:5]\n",
    "prediction_df[\"Label\"] = test_df[\"fraud\"].iloc[:5].values\n",
    "prediction_df "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "241703fe-cab1-4b27-ae6a-9f2ded94b389",
   "metadata": {},
   "source": [
    "Configure an auto scaling policy, minimun capacity is 1, maximum capacity "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6360acd-fa1e-4d6e-bd9a-dac44b191c99",
   "metadata": {},
   "outputs": [],
   "source": [
    "resp = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "\n",
    "# SageMaker expects resource id to be provided with the following structure\n",
    "resource_id = f\"endpoint/{endpoint_name}/variant/{resp['ProductionVariants'][0]['VariantName']}\"\n",
    "\n",
    "# Scaling configuration\n",
    "scaling_config_response = sm_autoscaling_client.register_scalable_target(\n",
    "                                                          ServiceNamespace=\"sagemaker\",\n",
    "                                                          ResourceId=resource_id,\n",
    "                                                          ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\", \n",
    "                                                          MinCapacity=1,\n",
    "                                                          MaxCapacity=2\n",
    "                                                        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b2045f2-36d2-4e2c-89fb-33a1597b5c05",
   "metadata": {},
   "source": [
    "Create the scaling policy. The scaling metric is SageMakerVariantInvocationsPerInstance (the average number of invocations per minute per model instance). When this number exceeds 5, auto scaling will be triggered."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3862463-a40b-446a-b821-0d108246864b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Scaling Policy\n",
    "policy_name = f\"scaling-policy-{endpoint_name}\"\n",
    "scaling_policy_response = sm_autoscaling_client.put_scaling_policy(\n",
    "                                                PolicyName=policy_name,\n",
    "                                                ServiceNamespace=\"sagemaker\",\n",
    "                                                ResourceId=resource_id,\n",
    "                                                ScalableDimension=\"sagemaker:variant:DesiredInstanceCount\",\n",
    "                                                PolicyType=\"TargetTrackingScaling\",\n",
    "                                                TargetTrackingScalingPolicyConfiguration={\n",
    "                                                    \"TargetValue\": 5.0, # Target for avg invocations per minutes\n",
    "                                                    \"PredefinedMetricSpecification\": {\n",
    "                                                        \"PredefinedMetricType\": \"SageMakerVariantInvocationsPerInstance\",\n",
    "                                                    },\n",
    "                                                    \"ScaleInCooldown\": 600, # Duration in seconds until scale in\n",
    "                                                    \"ScaleOutCooldown\": 60 # Duration in seconds between scale out\n",
    "                                                }\n",
    "                                            )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc83435f-a2b2-448f-a885-7db0bf8a7fd1",
   "metadata": {},
   "source": [
    "This code retrieves the scaling policy details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9724ce-08de-455f-8846-caedf51ca5dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "response = sm_autoscaling_client.describe_scaling_policies(ServiceNamespace=\"sagemaker\")\n",
    "\n",
    "pp = pprint.PrettyPrinter(indent=4, depth=4)\n",
    "for i in response[\"ScalingPolicies\"]:\n",
    "    pp.pprint(i[\"PolicyName\"])\n",
    "    print(\"\")\n",
    "    if(\"TargetTrackingScalingPolicyConfiguration\" in i):\n",
    "        pp.pprint(i[\"TargetTrackingScalingPolicyConfiguration\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28791b58-ed56-43eb-9c4f-5f14c8726b60",
   "metadata": {},
   "source": [
    "Stress test the endpoint to trigger auto scaling. This code runs for 250 seconds and repeatedly invokes the endpoint using random  samples from the test dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b5eb019-a2ee-4214-8f90-56027b187f11",
   "metadata": {},
   "outputs": [],
   "source": [
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Endpoint will be tested for {request_duration} seconds\")\n",
    "while time.time() < end_time:\n",
    "    csv_file = io.StringIO()\n",
    "    test_sample = test_df.drop([\"fraud\"], axis=1).iloc[[np.random.randint(0, test_df.shape[0])]]\n",
    "    test_sample.to_csv(csv_file, sep=\",\", header=False, index=False)\n",
    "    payload = csv_file.getvalue()\n",
    "    response = sm_runtime_client.invoke_endpoint(\n",
    "                                                 EndpointName=endpoint_name,\n",
    "                                                 Body=payload,\n",
    "                                                 ContentType=\"text/csv\"\n",
    "                                                )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6f6327b4-b192-42b8-aef7-16642c84c42d",
   "metadata": {},
   "source": [
    "Check the status of the endpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56829f6d-702c-47c0-ab41-7746a36e4b6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the instance counts after the endpoint gets more load\n",
    "response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "endpoint_status = response[\"EndpointStatus\"]\n",
    "request_duration = 250\n",
    "end_time = time.time() + request_duration\n",
    "print(f\"Waiting for Instance count increase for a max of {request_duration} seconds. Please re run this cell in case the count does not change\")\n",
    "while time.time() < end_time:\n",
    "    response = sm_client.describe_endpoint(EndpointName=endpoint_name)\n",
    "    endpoint_status = response[\"EndpointStatus\"]\n",
    "    instance_count = response[\"ProductionVariants\"][0][\"CurrentInstanceCount\"]\n",
    "    print(f\"Status: {endpoint_status}\")\n",
    "    print(f\"Current Instance count: {instance_count}\")\n",
    "    if (endpoint_status==\"InService\") and (instance_count>1):\n",
    "        break\n",
    "    else:\n",
    "        time.sleep(15)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7190dc9-29d5-4fbe-8bd5-4717741a3054",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Delete model\n",
    "sm_client.delete_model(ModelName=model_name)\n",
    "\n",
    "# Delete endpoint configuration\n",
    "sm_client.delete_endpoint_config(EndpointConfigName=endpoint_config_name)\n",
    "\n",
    "# Delete endpoint\n",
    "sm_client.delete_endpoint(EndpointName=endpoint_name)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c91ad48b-60e8-4f3f-8006-af85f243ac61",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
